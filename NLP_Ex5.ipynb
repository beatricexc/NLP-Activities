{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Ex5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwlA9VbJ2ygf9G+DYCWDlh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatricexc/NLP-Activities/blob/main/NLP_Ex5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLm3bYLh_-7Z",
        "outputId": "0095e8fc-5348-41ad-9857-264604a692e8"
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> l\n",
            "\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [*] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: q\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_HZtju3DQRb",
        "outputId": "4f90af99-b23b-4c00-f0aa-18d2156ba023"
      },
      "source": [
        "#Exercise 6: Tokenisation in NLTK\n",
        "#a)\n",
        "from nltk import word_tokenize\n",
        "document= 'Tokenisation is really easy in NLTK'\n",
        "words = word_tokenize(document)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenisation', 'is', 'really', 'easy', 'in', 'NLTK']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFmrRW-BDJ1D",
        "outputId": "0456fe87-4f3d-4fd8-e734-9b4a7e13f633"
      },
      "source": [
        "#b) Part-of-speech (POS) tagging in NLTK\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "document = 'Tokenisation is really easy in NLTK'\n",
        "words = word_tokenize(document)\n",
        "words_with_pos_tags = pos_tag(words)\n",
        "for word, pos_tag in words_with_pos_tags:\n",
        "  print(word, pos_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenisation NN\n",
            "is VBZ\n",
            "really RB\n",
            "easy JJ\n",
            "in IN\n",
            "NLTK NNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EDo_1CKEtlo"
      },
      "source": [
        "Exercise 7: Extracting Bigrams in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ImlMwXGFso",
        "outputId": "d47b18a1-aa08-4bf1-ed16-c179a5772110"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams\n",
        "document = 'Tokenisation is really easy in NLTK'\n",
        "words = word_tokenize(document)\n",
        "words_with_pos_tags = pos_tag(words)\n",
        "bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
        "for first_element, second_element in bigrams_with_pos_tags:\n",
        "  print(first_element, second_element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Tokenisation', 'NN') ('is', 'VBZ')\n",
            "('is', 'VBZ') ('really', 'RB')\n",
            "('really', 'RB') ('easy', 'JJ')\n",
            "('easy', 'JJ') ('in', 'IN')\n",
            "('in', 'IN') ('NLTK', 'NNP')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqfZMD6G_GH",
        "outputId": "cb719690-0fdd-43af-c02a-c812307997db"
      },
      "source": [
        "#b) printing parts of bigram elements\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams\n",
        "document = 'Tokenisation is really easy in NLTK'\n",
        "words = word_tokenize(document)\n",
        "words_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
        "for first_element, second_element in bigrams_with_pos_tags:\n",
        "  first_word_of_bigram, first_word_pos_tag = first_element[0], first_element[1]\n",
        "  second_word_of_bigram, second_word_pos_tag = second_element[0], second_element[1]\n",
        "  print(first_word_of_bigram, first_word_pos_tag, second_word_of_bigram, second_word_pos_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenisation NN is VBZ\n",
            "is VBZ really RB\n",
            "really RB easy JJ\n",
            "easy JJ in IN\n",
            "in IN NLTK NNP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91coQQ3xI54-",
        "outputId": "221f09f7-11d0-42a2-9bcb-1772a29bc494"
      },
      "source": [
        "#c) computing the frequency of birgams\n",
        "\n",
        "def compute_frequency_of_bigrams(bigrams_with_pos_tags):\n",
        "  bigrams_with_frequencies = {}\n",
        "\n",
        "  for first_element, second_element in bigrams_with_pos_tags:\n",
        "    bigram_string = first_element[0] + ' '+second_element[0]\n",
        "    if bigram_string in bigrams_with_frequencies:\n",
        "      bigrams_with_frequencies[bigram_string] += 1\n",
        "    else: \n",
        "      bigrams_with_frequencies[bigram_string] =1\n",
        "  return bigrams_with_frequencies\n",
        "\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams\n",
        "document = 'The city of New York is often called New York city or simply New York'\n",
        "words = word_tokenize(document)\n",
        "words_with_pos_tags = pos_tag(words)\n",
        "bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
        "\n",
        "#get bigrams with frequencies using the compute_frequency_of_bigrams function\n",
        "bigrams_with_frequencies = compute_frequency_of_bigrams(bigrams_with_pos_tags)\n",
        "for bigram, frequency in bigrams_with_frequencies.items():\n",
        "  print(bigram,frequency)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The city 1\n",
            "city of 1\n",
            "of New 1\n",
            "New York 3\n",
            "York is 1\n",
            "is often 1\n",
            "often called 1\n",
            "called New 1\n",
            "York city 1\n",
            "city or 1\n",
            "or simply 1\n",
            "simply New 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fij2YCn1LUON",
        "outputId": "64675f4c-29c3-4bf7-d2f6-a8f095f53f9e"
      },
      "source": [
        "#d)sorting bigrams by frequency \n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams\n",
        "import operator\n",
        "document = 'The city of New York is often called New York city or simply New York'\n",
        "words = word_tokenize(document)\n",
        "words_with_pos_tags = pos_tag(words)\n",
        "\n",
        "bigrams_with_pos_tags = list(bigrams(words_with_pos_tags))\n",
        "\n",
        "#get bigrams with frequencies using the compute_frequency_of_bigrams functions\n",
        "bigrams_with_frequencies = compute_frequency_of_bigrams(bigrams_with_pos_tags)\n",
        "\n",
        "#sort dictionary by value\n",
        "bigrams_with_frequencies = dict(sorted(bigrams_with_frequencies.items(),\n",
        "                                       key = operator.itemgetter(1),\n",
        "                                       reverse=True))\n",
        "for bigram, frequency in bigrams_with_frequencies.items():\n",
        "  print(bigram, frequency)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New York 3\n",
            "The city 1\n",
            "city of 1\n",
            "of New 1\n",
            "York is 1\n",
            "is often 1\n",
            "often called 1\n",
            "called New 1\n",
            "York city 1\n",
            "city or 1\n",
            "or simply 1\n",
            "simply New 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8vO-ljBNcmm",
        "outputId": "dd2fb5bc-9458-48bf-a811-5d1d47b4ce1f"
      },
      "source": [
        "#Exercise 8 \n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk import bigrams\n",
        "import operator\n",
        "import math\n",
        "document = 'The City of New York is often called New York City or simply New York'\n",
        "words = word_tokenize(document)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'City', 'of', 'New', 'York', 'is', 'often', 'called', 'New', 'York', 'City', 'or', 'simply', 'New', 'York']\n"
          ]
        }
      ]
    }
  ]
}